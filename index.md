---
layout: default
---

Hi, my name is Yu Zhang ([jy tʃɑŋ], 張宇/张宇 in traditional/simplified Chinese).
I am currently a third-year PhD student at [HLT@SUDA](http://hlt.suda.edu.cn), advised by [Prof. Guohong Fu](http://web.suda.edu.cn/ghfu/).
I expect to graduate in 2025. 
Prior to this, I received my M. Eng. degree from Soochow University in 2021.
  
My early research focused on structured prediction tasks, specifically dependency parsing and constituency parsing. 
Currently, my research interests have evolved to focus on developing efficient text generation models. 
I am particularly intrigued by the prospect of developing hardware-efficient methods for linear-time sequence modeling. 
As a disciple of parallel programming, I am passionate about exploring techniques that harness the power of parallel computing to develop scalable subquadratic models.

### Publications:

[[Semantic Scholar](https://www.semanticscholar.org/author/Yu-Zhang/49890808)] [[Google Scholar](https://scholar.google.com/citations?user=y3JK-1oAAAAJ)] [[DBLP](https://dblp.org/pid/50/671-92.html)] (\* denotes equal contributions)

* Gated Slot Attention for Efficient Linear-Time Sequence Modeling <br>
**Yu Zhang**\*, Songlin Yang\*, Ruijie Zhu, Yue Zhang, Leyang Cui, Yiqiao Wang, Bolun Wang, Freda Shi, Bailin Wang, Wei Bi, Peng Zhou, Guohong Fu<br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/gsa.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2409.07146)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/sustcsonglin/flash-linear-attention)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3d3b13ae755b87aa1425e2294263186bc8723740%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Gated-Slot-Attention-for-Efficient-Linear-Time-Zhang-Yang/3d3b13ae755b87aa1425e2294263186bc8723740)

* Parallelizing Linear Transformers with the Delta Rule over Sequence Length <br>
Songlin Yang, Bailin Wang, **Yu Zhang**, Yikang Shen, Yoon Kim <br>
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2406.06484)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/sustcsonglin/flash-linear-attention)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd3d1acfe37fe8d98e06dcf63b6e6dbe90cca061d%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Parallelizing-Linear-Transformers-with-the-Delta-Yang-Wang/d3d1acfe37fe8d98e06dcf63b6e6dbe90cca061d)

* Scalable MatMul-free Language Modeling <br>
Rui-Jie Zhu, **Yu Zhang**, Ethan Sifferman, Tyler Sheaves, Yiqiao Wang, Dustin Richmond, Peng Zhou, Jason K. Eshraghian <br>
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2406.02528)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/ridgerchu/matmulfreellm/)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F401c4147375b016d4758cf2dd859232a8271fdcd%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Scalable-MatMul-free-Language-Modeling-Zhu-Zhang/401c4147375b016d4758cf2dd859232a8271fdcd)

* Non-autoregressive Text Editing with Copy-aware Latent Alignments <br>
**Yu Zhang**\*, Yue Zhang\*, Leyang Cui, Guohong Fu <br>
**EMNLP 2023** <br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/emnlp/2023/ctc.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2310.07821)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/emnlp/2023/ctc.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/yzhangcs/ctc-copy)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F116277fd27c97d50bba2d8023d3c590c1ea8187b%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Non-autoregressive-Text-Editing-with-Copy-aware-Zhang-Zhang/116277fd27c97d50bba2d8023d3c590c1ea8187b)

* Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments <br>
**Yu Zhang**, Qingrong Xia, Shilin Zhou, Yong Jiang, Guohong Fu, Min Zhang <br>
**COLING 2022** <br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/coling/2022/crfsrl.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2110.06865)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/coling/2022/crfsrl.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/yzhangcs/crfsrl)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F64332d61dfef5ac685500a238b8a79d75152c164%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Semantic-Role-Labeling-as-Dependency-Parsing%3A-Tree-Zhang-Xia/64332d61dfef5ac685500a238b8a79d75152c164)

* Fast and Accurate End-to-End Span-based Semantic Role Labeling as Word-based Graph Parsing <br>
Shilin Zhou, Qingrong Xia, Zhenghua Li, **Yu Zhang**, Yu Hong, Min Zhang <br>
**COLING 2022** (<strong><i style="color:#e74d3c">Best Paper Award</i></strong>)<br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/coling/2022/graphsrl.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2112.02970)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/coling/2022/graphsrl.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/zsLin177/SRL-as-GP)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fea9a2d14672c3cc0ff92510386f46fb2b152570c%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Fast-and-Accurate-End-to-End-Span-based-Semantic-as-Zhou-Xia/ea9a2d14672c3cc0ff92510386f46fb2b152570c)

* Fast and Accurate Neural CRF Constituency Parsing <br>
**Yu Zhang**\*, Houquan Zhou\*, Zhenghua Li <br>
**IJCAI 2020** <br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/ijcai/2020/crfpar.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2008.03736)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/ijcai/2020/crfpar.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/yzhangcs/crfpar)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F46fe2ae301aeb75b25ebca0bdc26132ca46f5101%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Fast-and-Accurate-Neural-CRF-Constituency-Parsing-Zhang-Zhou/46fe2ae301aeb75b25ebca0bdc26132ca46f5101)

* Efficient Second-Order TreeCRF for Neural Dependency Parsing <br>
**Yu Zhang**, Zhenghua Li, Min Zhang <br>
**ACL 2020** <br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/acl/2020/crfpar.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2005.00975)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/acl/2020/crfpar.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/yzhangcs/crfpar)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fce18780963b067a1295fc847e7ab33f2fcbfaca1%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Efficient-Second-Order-TreeCRF-for-Neural-Parsing-Zhang-Li/ce18780963b067a1295fc847e7ab33f2fcbfaca1)

* Is POS Tagging Necessary or Even Helpful for Neural Dependency Parsing?<br>
Houquan Zhou\*, **Yu Zhang**\*, Zhenghua Li, Min Zhang <br>
**NLPCC 2020** (<strong><i style="color:#e74d3c">Best Paper Award</i></strong>)<br>
[![paper](https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/nlpcc/2020/posdep.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/2003.03204)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/nlpcc/2020/posdep.bib)
[![code](https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github)](https://github.com/Jacob-Zhou/stack-parser)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3bb577d87ae8e0d45a223f65db24ab479fbda174%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/Is-POS-Tagging-Necessary-or-Even-Helpful-for-Neural-Zhang-Li/3bb577d87ae8e0d45a223f65db24ab479fbda174)

* HLT@SUDA at SemEval-2019 Task 1: UCCA Graph Parsing as Constituent Tree Parsing <br>
Wei Jiang, Zhenghua Li, **Yu Zhang**, Min Zhang <br>
**SemEval 2019** <br>
[![paper](https://img.shields.io/badge/paper-d6d6d6?style=flat-square)](https://yzhang.site/assets/pubs/semeval/2019/const.pdf)
[![arxiv](https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square)](https://arxiv.org/abs/1903.04153)
[![bib](https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square)](https://yzhang.site/assets/pubs/semeval/2019/const.bib)
[![code](https://img.shields.io/badge/code-d6d6d6?style=flat-square&logo=github)](https://github.com/SUDA-LA/ucca-parser)
[![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9c690b828a508635506018ddbd03d63d4e08a380%3Ffields%3DcitationCount&color=d6d6d6&style=flat-square&logo=semanticscholar)](https://www.semanticscholar.org/paper/HLT%40SUDA-at-SemEval-2019-Task-1%3A-UCCA-Graph-Parsing-Jiang-Zhang/9c690b828a508635506018ddbd03d63d4e08a380)

### Projects:

* **FLA**: A Triton-Based Library for Hardware-Efficient Implementations of Linear Attention Mechanism <br>
[![code](https://img.shields.io/badge/code-orange?style=flat-square&logo=github)](https://github.com/sustcsonglin/flash-linear-attention)
<br>

* **SuPar**: State-of-the-art syntactic/semantic parsers <br>
[![code](https://img.shields.io/badge/code-orange?style=flat-square&logo=github)](https://github.com/yzhangcs/parser)
[![docs](https://img.shields.io/github/actions/workflow/status/yzhangcs/parser/pages.yml?branch=main&label=docs&style=flat-square)](https://parser.yzhang.site)
[![release](https://img.shields.io/github/v/release/yzhangcs/parser?style=flat-square)](https://github.com/yzhangcs/parser/releases)
[![downloads](https://img.shields.io/github/downloads/yzhangcs/parser/total?style=flat-square)](https://pypistats.org/packages/supar)
<br>
A Python package designed for structured prediction, including reproductions of many state-of-the-art syntactic/semantic parsers (with pretrained models for more than 19 languages), and highly-parallelized implementations of several well-known structured prediction algorithms.

### Thesis:

* TreeCRF-based High-Order Syntactic Parsing. Master Thesis, Soochow University, 2021 <br>
[![pdf](https://img.shields.io/badge/pdf-d6d6d6?style=flat-square)](https://yzhang.site/assets/pubs/master-thesis.pdf)
[![latex](https://img.shields.io/badge/latex-d6d6d6?style=flat-square&logo=github)](https://github.com/yzhangcs/master-thesis)
<br>

### Experience

* 2021 - present. PhD student at Soochow University, advised by [Prof. Guohong Fu](http://web.suda.edu.cn/ghfu/).
* 2023 - 2024. Research Intern at Tencent AI Lab, mentored by [Wei Bi](https://scholar.google.com/citations?user=aSJcgQMAAAAJ&hl=en).
* 2020 - 2021. Research Intern at Alibaba DAMO Academy, mentored by [Yong Jiang](http://jiangyong.site).
* 2018 - 2021: M.S. student at Soochow University, advised by [Prof. Zhenghua Li](http://hlt.suda.edu.cn/~zhli).
