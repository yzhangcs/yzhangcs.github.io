---
layout: default
---

Hi, my name is Yu Zhang ([jy tʃɑŋ], 張宇/张宇 in traditional/simplified Chinese).
I am a researcher at [Moonshot AI](https://www.moonshot.cn/).

I received my Ph.D. degree from Soochow University in 2025, advised by [Prof. Guohong Fu](http://web.suda.edu.cn/ghfu/).
Prior to this, I received my M. Eng. and B. Eng. degrees from Soochow University in 2021 and 2018, respectively.

~~*My early research focused on structured prediction tasks, specifically dependency parsing and constituency parsing.*~~
Currently, my research interests have evolved to focus on developing efficient text generation models.
I am particularly intrigued by the prospect of developing hardware-efficient methods for linear-time sequence modeling.
As a disciple of parallel programming, I am passionate about exploring techniques that harness the power of parallel computing to develop scalable subquadratic models.

## Publications

<div class="pub-links">
  <a href="https://www.semanticscholar.org/author/Yu-Zhang/49890808">Semantic Scholar</a>
  <a href="https://scholar.google.com/citations?user=y3JK-1oAAAAJ">Google Scholar</a>
  <a href="https://dblp.org/pid/50/671-92.html">DBLP</a>
</div>
<p class="pub-note">* denotes equal contributions</p>

<div class="pub-list">

<div class="pub-card">
  <div class="pub-title">Kimi Linear: An Expressive, Eﬀicient Attention Architecture</div>
  <div class="pub-authors"><strong>Yu Zhang</strong>, Zongyu Lin, Xingcheng Yao, Jiaxi Hu, Fanqing Meng, Chengyin Liu, Xin Men, Songlin Yang, Zhiyuan Li, Wentao Li, Enzhe Lu, Weizhou Liu, Yanru Chen, Weixin Xu, Longhui Yu, Yejie Wang, Yu Fan, Longguang Zhong, Enming Yuan, Dehao Zhang, Yizhi Zhang, TY Liu, Haiming Wang, Shengjun Fang, Weiran He, Shaowei Liu, Yiwei Li, Jianlin Su, Jiezhong Qiu, Bo Pang, Junjie Yan, Zhejun Jiang, Weixiao Huang, Bohong Yin, Jiacheng You, Chu Wei, Zhengtao Wang, Chao Hong, Yutian Chen, Guanduo Chen, Yucheng Wang, Huabin Zheng, Feng Wang, Yibo Liu, Mengnan Dong, Zheng Zhang, Siyuan Pan, Wenhao Wu, Yuhao Wu, Longyu Guan, Jiawen Tao, Guohong Fu, Xinran Xu, Yuzhi Wang, Guokun Lai, Yuxin Wu, Xinyu Zhou, Zhilin Yang, Yulun Du</div>
  <div class="pub-venue"><span class="venue-badge preprint">Preprint</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/techreport/2025/kda.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/techreport/2025/kda.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2510.26692"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/MoonshotAI/Kimi-Linear"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Kimi-Linear%3A-An-Expressive%2C-Efficient-Attention-Zhang-Lin/fc6412d9ec7a6a07ce9ef15273279a0021d09422"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Gated Slot Attention for Efficient Linear-Time Sequence Modeling</div>
  <div class="pub-authors"><strong>Yu Zhang*</strong>, Songlin Yang*, Ruijie Zhu, Yue Zhang, Leyang Cui, Yiqiao Wang, Bolun Wang, Freda Shi, Bailin Wang, Wei Bi, Peng Zhou, Guohong Fu</div>
  <div class="pub-venue"><span class="venue-badge conf">NeurIPS 2024</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/neurips/2024/gsa.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/neurips/2024/gsa.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2409.07146"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/sustcsonglin/flash-linear-attention"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Gated-Slot-Attention-for-Efficient-Linear-Time-Zhang-Yang/3d3b13ae755b87aa1425e2294263186bc8723740"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Parallelizing Linear Transformers with the Delta Rule over Sequence Length</div>
  <div class="pub-authors">Songlin Yang, Bailin Wang, <strong>Yu Zhang</strong>, Yikang Shen, Yoon Kim</div>
  <div class="pub-venue"><span class="venue-badge conf">NeurIPS 2024</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/neurips/2024/deltanet.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/neurips/2024/deltanet.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2406.06484"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/sustcsonglin/flash-linear-attention"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Parallelizing-Linear-Transformers-with-the-Delta-Yang-Wang/7afaabb73bec969c0937be46b9f0f757e07c8534"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Scalable MatMul-free Language Modeling</div>
  <div class="pub-authors">Ruijie Zhu, <strong>Yu Zhang</strong>, Ethan Sifferman, Tyler Sheaves, Yiqiao Wang, Dustin Richmond, Peng Zhou, Jason K. Eshraghian</div>
  <div class="pub-venue"><span class="venue-badge preprint">Preprint</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/neurips/2024/mmf.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/neurips/2024/mmf.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2406.02528"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/ridgerchu/matmulfreellm/"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Scalable-MatMul-free-Language-Modeling-Zhu-Zhang/401c4147375b016d4758cf2dd859232a8271fdcd"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Non-autoregressive Text Editing with Copy-aware Latent Alignments</div>
  <div class="pub-authors"><strong>Yu Zhang*</strong>, Yue Zhang*, Leyang Cui, Guohong Fu</div>
  <div class="pub-venue"><span class="venue-badge conf">EMNLP 2023</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/emnlp/2023/ctc.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/emnlp/2023/ctc.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2310.07821"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/yzhangcs/ctc-copy"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Non-autoregressive-Text-Editing-with-Copy-aware-Zhang-Zhang/116277fd27c97d50bba2d8023d3c590c1ea8187b"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments</div>
  <div class="pub-authors"><strong>Yu Zhang</strong>, Qingrong Xia, Shilin Zhou, Yong Jiang, Guohong Fu, Min Zhang</div>
  <div class="pub-venue"><span class="venue-badge conf">COLING 2022</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/coling/2022/crfsrl.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/coling/2022/crfsrl.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2110.06865"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/yzhangcs/crfsrl"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Semantic-Role-Labeling-as-Dependency-Parsing%3A-Tree-Zhang-Xia/64332d61dfef5ac685500a238b8a79d75152c164"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Fast and Accurate End-to-End Span-based Semantic Role Labeling as Word-based Graph Parsing <span class="award-badge">Best Paper Award</span></div>
  <div class="pub-authors">Shilin Zhou, Qingrong Xia, Zhenghua Li, <strong>Yu Zhang</strong>, Yu Hong, Min Zhang</div>
  <div class="pub-venue"><span class="venue-badge conf">COLING 2022</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/coling/2022/graphsrl.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/coling/2022/graphsrl.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2112.02970"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/zsLin177/SRL-as-GP"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Fast-and-Accurate-End-to-End-Span-based-Semantic-as-Zhou-Xia/ea9a2d14672c3cc0ff92510386f46fb2b152570c"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Fast and Accurate Neural CRF Constituency Parsing</div>
  <div class="pub-authors"><strong>Yu Zhang*</strong>, Houquan Zhou*, Zhenghua Li</div>
  <div class="pub-venue"><span class="venue-badge conf">IJCAI 2020</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/ijcai/2020/crfpar.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/ijcai/2020/crfpar.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2008.03736"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/yzhangcs/crfpar"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Fast-and-Accurate-Neural-CRF-Constituency-Parsing-Zhang-Zhou/46fe2ae301aeb75b25ebca0bdc26132ca46f5101"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Efficient Second-Order TreeCRF for Neural Dependency Parsing</div>
  <div class="pub-authors"><strong>Yu Zhang</strong>, Zhenghua Li, Min Zhang</div>
  <div class="pub-venue"><span class="venue-badge conf">ACL 2020</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/acl/2020/crfpar.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/acl/2020/crfpar.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2005.00975"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/yzhangcs/crfpar"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Efficient-Second-Order-TreeCRF-for-Neural-Parsing-Zhang-Li/ce18780963b067a1295fc847e7ab33f2fcbfaca1"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">Is POS Tagging Necessary or Even Helpful for Neural Dependency Parsing? <span class="award-badge">Best Paper Award</span></div>
  <div class="pub-authors">Houquan Zhou*, <strong>Yu Zhang*</strong>, Zhenghua Li, Min Zhang</div>
  <div class="pub-venue"><span class="venue-badge conf">NLPCC 2020</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/nlpcc/2020/posdep.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/nlpcc/2020/posdep.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/2003.03204"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/Jacob-Zhou/stack-parser"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/Is-POS-Tagging-Necessary-or-Even-Helpful-for-Neural-Zhang-Li/3bb577d87ae8e0d45a223f65db24ab479fbda174"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

<div class="pub-card">
  <div class="pub-title">HLT@SUDA at SemEval-2019 Task 1: UCCA Graph Parsing as Constituent Tree Parsing</div>
  <div class="pub-authors">Wei Jiang, Zhenghua Li, <strong>Yu Zhang</strong>, Min Zhang</div>
  <div class="pub-venue"><span class="venue-badge conf">SemEval 2019</span></div>
  <div class="pub-badges">
    <a href="https://yzhang.site/assets/pubs/semeval/2019/const.pdf"><img src="https://img.shields.io/badge/paper-d6d6d6.svg?style=flat-square&logo=overleaf" alt="paper"></a>
    <a href="https://yzhang.site/assets/pubs/semeval/2019/const.bib"><img src="https://img.shields.io/badge/bib-d6d6d6.svg?style=flat-square" alt="bib"></a>
    <a href="https://arxiv.org/abs/1903.04153"><img src="https://img.shields.io/badge/arxiv-d6d6d6.svg?style=flat-square&logo=arxiv&logoColor=b31b1b" alt="arxiv"></a>
    <a href="https://github.com/SUDA-LA/ucca-parser"><img src="https://img.shields.io/badge/code-d6d6d6.svg?style=flat-square&logo=github&logoColor=181717" alt="code"></a>
    <a href="https://www.semanticscholar.org/paper/HLT%40SUDA-at-SemEval-2019-Task-1%3A-UCCA-Graph-Parsing-Jiang-Zhang/6c690b828a508635506018ddbd03d63d4e08a380"><img src="https://img.shields.io/badge/citation-0-d6d6d6.svg?style=flat-square&logo=semanticscholar" alt="citation"></a>
  </div>
</div>

</div>

## Projects

<div class="project-list">

<div class="project-card">
  <div class="project-header">
    <span class="project-name">FLA</span>
    <div class="project-badges">
      <a href="https://github.com/fla-org/flash-linear-attention">
        <img src="https://img.shields.io/badge/code-orange?style=flat-square&logo=github" alt="code">
      </a>
      <a href="https://github.com/fla-org/flash-linear-attention/releases">
        <img src="https://img.shields.io/github/v/release/fla-org/flash-linear-attention?style=flat-square" alt="release">
      </a>
    </div>
  </div>
  <div class="project-desc">A Triton-Based Library for Hardware-Efficient Implementations of Linear Attention Mechanism</div>
</div>

<div class="project-card">
  <div class="project-header">
    <span class="project-name">SuPar</span>
    <div class="project-badges">
      <a href="https://github.com/yzhangcs/parser">
        <img src="https://img.shields.io/badge/code-orange?style=flat-square&logo=github" alt="code">
      </a>
      <a href="https://github.com/yzhangcs/parser/releases">
        <img src="https://img.shields.io/github/v/release/yzhangcs/parser?style=flat-square" alt="release">
      </a>
    </div>
  </div>
  <div class="project-desc">State-of-the-art syntactic/semantic parsers. A Python package designed for structured prediction, including reproductions of many state-of-the-art syntactic/semantic parsers (with pretrained models for more than 19 languages), and highly-parallelized implementations of several well-known structured prediction algorithms.</div>
</div>

</div>

## Experience

<div class="exp-list">

<div class="exp-card">
  <div class="exp-date">2025 - present</div>
  <div class="exp-title">AI Researcher at Moonshot AI</div>
</div>

<div class="exp-card">
  <div class="exp-date">2024 - 2025</div>
  <div class="exp-title">Research Intern at Shanghai AI Lab</div>
  <div class="exp-mentor">mentored by <a href="https://scholar.google.com/citations?user=ZyqFanQAAAAJ">Peng Gao</a></div>
</div>

<div class="exp-card">
  <div class="exp-date">2023 - 2024</div>
  <div class="exp-title">Research Intern at Tencent AI Lab</div>
  <div class="exp-mentor">mentored by <a href="https://scholar.google.com/citations?user=aSJcgQMAAAAJ">Wei Bi</a></div>
</div>

<div class="exp-card">
  <div class="exp-date">2020 - 2021</div>
  <div class="exp-title">Research Intern at Alibaba DAMO Academy</div>
  <div class="exp-mentor">mentored by <a href="http://jiangyong.site">Yong Jiang</a></div>
</div>

</div>
