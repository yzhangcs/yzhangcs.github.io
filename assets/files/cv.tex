\documentclass[a4paper,12pt]{article}

%A Few Useful Packages
\usepackage{marvosym}
\usepackage{fontspec} 					%for loading fonts
\usepackage{xunicode,xltxtra,url,parskip} 	%other packages for formatting
\RequirePackage{color,graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[big]{layaureo} 				%better formatting of the A4 page
% an alternative to Layaureo can be ** \usepackage{fullpage} **
\usepackage{supertabular} 				%for Grades
\usepackage{titlesec}					%custom \section

%Setup hyperref package, and colours for links
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{fontawesome}
\usepackage{lipsum}
\usepackage{enumitem}
% \usepackage{mathptmx}

\definecolor{brickred}{HTML}{b92622}
\definecolor{linkcolour}{rgb}{0,0.2,0.6}
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour, linkcolor=linkcolour}

\newcommand{\github}{\faGithub}

%FONTS
% \defaultfontfeatures{Mapping=tex-text}
% %\setmainfont[SmallCapsFont = Fontin SmallCaps]{Fontin}
% %%% modified for Karol Kozio≈Ç for ShareLaTeX use
% \setmainfont[
% SmallCapsFont = Fontin-SmallCaps.otf,
% BoldFont = Fontin-Bold.otf,
% ItalicFont = Fontin-Italic.otf
% ]
% {Fontin.otf}
%%%
\linespread{1.2}

%CV Sections inspired by:
%http://stefano.italians.nl/archives/26
\titleformat{\section}{\color{brickred}\Large\scshape\raggedright}{}{0em}{}[\color{black}\hrule height 0.3mm]
\titlespacing{\section}{0pt}{8pt}{8pt}
%Tweak a bit the top margin
%\addtolength{\voffset}{-1.3cm}

%Italian hyphenation for the word: ''corporations''
\hyphenation{im-pre-se}

%-------------WATERMARK TEST [**not part of a CV**]---------------
\usepackage[absolute]{textpos}

\setlength{\TPHorizModule}{30mm}
\setlength{\TPVertModule}{\TPHorizModule}
\textblockorigin{2mm}{0.65\paperheight}
\setlength{\parindent}{0pt}

%--------------------BEGIN DOCUMENT----------------------
\begin{document}

%WATERMARK TEST [**not part of a CV**]---------------
%\font\wm=''Baskerville:color=787878'' at 8pt
%\font\wmweb=''Baskerville:color=FF1493'' at 8pt
%{\wm
%	\begin{textblock}{1}(0,0)
%		\rotatebox{-90}{\parbox{500mm}{
%			Typeset by Alessandro Plasmati with \XeTeX\  \today\ for
%			{\wmweb \href{http://www.aleplasmati.comuv.com}{aleplasmati.comuv.com}}
%		}
%	}
%	\end{textblock}
%}

\pagestyle{empty} % non-numbered pages

\font\fb=''[cmr10]'' %for use with \LaTeX command

%--------------------TITLE-------------
\par{{\LARGE \textsc{Yu Zhang}}\bigskip\par}

%--------------------SECTIONS-----------------------------------
%Section: Personal Data

\begin{tabularx}{\textwidth}{@{}lll}
      Soochow University                       & \faEnvelope & \href{mailto:yzhang.cs@outlook.com}{\texttt{yzhang.cs@outlook.com}}      \\
      Institute of Artificial Intelligence     & \faGithub   & \href{https://github.com/yzhangcs}{\texttt{https://github.com/yzhangcs}} \\
      School of Computer Science \& Technology & \faTwitter  & \href{https://twitter.com/yzhang_cs}{\texttt{https://twitter.com/yzhang\_cs}} \\
      Suzhou, China                            & \faHome     & \href{https://yzhang.site}{\texttt{https://yzhang.site}}
\end{tabularx}

\section{Profile}
I am a fourth-year PhD student at HLT@SUDA, advised by Prof. Guohong Fu, and expect to graduate in 2025.
Prior to this, I received my M. Eng. degree from Soochow University in 2021. 

\textcolor{gray}{\emph{My early research focused on structured prediction tasks, specifically dependency parsing and constituency parsing.}}
Currently, my research interests have evolved to focus on developing efficient text generation models.
I am particularly intrigued by the prospect of developing hardware-efficient methods for linear-time sequence modeling.
As a disciple of parallel programming, I am passionate about exploring techniques that harness the power of parallel computing to develop scalable subquadratic models.

In March 2025 I joined \href{https://www.moonshot.ai/}{Moonshot AI} as a full-time researcher.

\section{Publications}
\textcolor{gray}{\emph{$^*$ denotes equal contributions}}

%\href{https://www.semanticscholar.org/author/Yu-Zhang/49890808}{[Semantic Scholar]}
%\href{https://scholar.google.com/citations?user=y3JK-1oAAAAJ}{[Google Scholar]}
%\href{https://dblp.org/pid/50/671-92.html}{[DBLP]}

\begin{itemize}[leftmargin=18pt]
      \item Gated Slot Attention for Efficient Linear-Time Sequence Modeling \\
            \textbf{Yu Zhang$^*$}, Songlin Yang$^*$, Ruijie Zhu, Yue Zhang, Leyang Cui, Yiqiao Wang, Bolun Wang, Freda Shi, Bailin Wang, Wei Bi, Peng Zhou, Guohong Fu \\
            \textbf{NeurIPS 2024}
      \item Parallelizing Linear Transformers with the Delta Rule over Sequence Length \\
            Songlin Yang, Bailin Wang, \textbf{Yu Zhang}, Yikang Shen, Yoon Kim \\
            \textbf{NeurIPS 2024}
      \item Scalable MatMul-free Language Modeling \\
            Ruijie Zhu, \textbf{Yu Zhang}, Ethan Sifferman, Tyler Sheaves, Yiqiao Wang, Dustin Richmond, Peng Zhou, Jason K. Eshraghian \\
            \textbf{Preprint}
      \item Non-autoregressive Text Editing with Copy-aware Latent Alignments \\
            \textbf{Yu Zhang$^*$}, Yue Zhang$^*$, Leyang Cui, Guohong Fu\\
            \textbf{EMNLP 2023}
      \item Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree Structures Inside Arguments\\
            \textbf{Yu Zhang}, Qingrong Xia, Shilin Zhou, Yong Jiang, Guohong Fu, Min Zhang\\
            \textbf{COLING 2022}
      \item Fast and Accurate End-to-End Span-based Semantic Role Labeling as Word-based Graph Parsing\\
            Shilin Zhou, Qingrong Xia, Zhenghua Li, \textbf{Yu Zhang}, Yu Hong, Min Zhang\\
            \textbf{COLING 2022} (\textbf{\emph{\textcolor{brickred}{Best Paper Award}}})
      \item Fast and Accurate Neural CRF Constituency Parsing\\
            \textbf{Yu Zhang$^*$}, Houquan Zhou$^*$, Zhenghua Li\\
            \textbf{IJCAI 2020}
      \item Efficient Second-Order TreeCRF for Neural Dependency Parsing\\
            \textbf{Yu Zhang}, Zhenghua Li, Min Zhang\\
            \textbf{ACL 2020}
      \item Is POS Tagging Necessary or Even Helpful for Neural Dependency Parsing?\\
            Houquan Zhou$^*$, \textbf{Yu Zhang$^*$}, Zhenghua Li, Min Zhang\\
            \textbf{NLPCC 2020} (\textbf{\emph{\textcolor{brickred}{Best Paper Award}}})
      \item HLT@SUDA at SemEval-2019 Task 1: UCCA Graph Parsing as Constituent Tree Parsing\\
            Wei Jiang, Zhenghua Li, \textbf{Yu Zhang}, Min Zhang\\
            \textbf{SemEval 2019}
\end{itemize}

\section{Projects}
\begin{itemize}[leftmargin=18pt]
      \item \href{https://github.com/sustcsonglin/flash-linear-attention}{\textbf{FLA}} (\textbf{\emph{\textcolor{brickred}{3.1K stars}}}): A Triton-Based Library for Hardware-Efficient Implementations of Linear Attention Mechanism.
      \item \href{https://github.com/yzhangcs/parser}{\textbf{SuPar}} (\textbf{\emph{\textcolor{brickred}{~1K stars}}}): A Python package designed for structured prediction, including reproductions of many state-of-the-art syntactic/semantic parsers (with pretrained models for more than 19 languages), and highly-parallelized implementations of several well-known structured prediction algorithms.
\end{itemize}

%Section: Education
\section{Education}
\begin{itemize}[leftmargin=18pt]
      \item 2021 - present. \emph{PhD student} at \textbf{Soochow University}, advised by Prof. Guohong Fu.
      \item 2018 - 2021: \emph{Master student} at \textbf{Soochow University}, advised by Prof. Zhenghua Li.
      \item 2014 - 2018. \emph{Bachelor of Engineering} from \textbf{Soochow University}.
\end{itemize}

\section{Experience}
\begin{itemize}[leftmargin=18pt]
      \item 2024 - 2025 - present. AI researcher at \textbf{Moonshot AI}.
      \item 2024 - 2025. \emph{Research Intern} at \textbf{Shanghai AI Lab}, mentored by Peng Gao.
      \item 2023 - 2024. \emph{Research Intern} at \textbf{Tencent AI Lab}, mentored by Wei Bi.
      \item 2020 - 2021. \emph{Research Intern} at \textbf{Alibaba DAMO Academy}, mentored by Yong Jiang.
\end{itemize}

\end{document}
